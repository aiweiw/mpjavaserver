# coding=utf-8

import os
import re
import numpy as np
import time
import sys

from matrix_learn import load_model
from matrix_seg import seg_cont_ansj, seg_cont_jieba, seg_sentence, seg_sent_base

"""
generate oneline-vec jieba
"""


def matrix_line_jieba(content, model, tfidf=None, avg_tfidf=None, tfidf_max_num=1, sen_vec_method=0, dim=100):
    """
    :param content: line-contnet to generate matrix
    :param model: word-vector-model-learned
    :param tfidf: all-files-tfidf number
    :param avg_tfidf: max-min-avg tfidf-number
    :param tfidf_max_num: every-line-weight generated by tfidf-num
    :param sen_vec_method: if weight-vector
    :param dim: word-vector-dim
    :return:
    """
    if not content or not model:
        return None

    if sys.getdefaultencoding() != 'utf-8':
        reload(sys)
        sys.setdefaultencoding('utf-8')

    line_list = seg_sent_base(content)

    matrix_content = list()
    content_tfidf = list()

    for line_one in line_list:
        if line_one == '\n' or line_one == '\n\n':
            continue
        line_vec = np.zeros(dim)
        line_tfidf = list()
        word_num = 0
        # if ansj_serve_url:
        #     words = seg_cont_ansj(line_one, ansj_serve_url)
        # else:
        #     words_jieba = seg_cont_jieba(line_one)
        #     words = [word for word, flag in words_jieba]
        words_jieba = seg_cont_jieba(line_one)
        words = [word for word, flag in words_jieba]
        # TODO: update word-vector to sentence-vector by NN or ...
        for word in words:
            word = ''.join(word.split())
            if word == ' ' or word == '\n' or word == '\n\n':
                continue

            # line-vec
            if sen_vec_method == 0:
                # mean-words to sentence-vector
                line_vec += np.array(model[word])
                word_num += 1
            elif sen_vec_method == 1 and tfidf and avg_tfidf:
                # zero tfidf dealwith no-words
                if word.encode('utf-8') in tfidf:
                    line_vec += np.array(model[word]) * tfidf[word.encode('utf-8')]
                    # else:
                    #     pass
            # elif sen_vec_method == 2 and tfidf and avg_tfidf:
            #     # mininum tfidf dealwith no-words
            #     if word.encode('utf-8') in tfidf:
            #         line_vec += np.array(model[word]) * tfidf[word.encode('utf-8')]
            #     else:
            #         line_vec += np.array(model[word]) * avg_tfidf['mininum']
            # elif sen_vec_method == 3 and tfidf and avg_tfidf:
            #     # normlize tfidf
            #     if word.encode('utf-8') in tfidf:
            #         line_vec += np.array(model[word]) * (tfidf[word.encode('utf-8')] - avg_tfidf['mininum']) \
            #                     / (avg_tfidf['maxinum'] - avg_tfidf['mininum'])
            #     else:
            #         line_vec += np.array(model[word]) * (avg_tfidf['average'] - avg_tfidf['mininum']) \
            #                     / (avg_tfidf['maxinum'] - avg_tfidf['mininum'])
            else:
                # default: mean-words-vector to sentence-vector
                line_vec += np.array(model[word])
                word_num += 1
                # pass

            # line-weight
            if tfidf and word.encode('utf-8') in tfidf:
                line_tfidf.append(tfidf[word.encode('utf-8')])
            elif avg_tfidf:
                line_tfidf.append(avg_tfidf['mininum'])
            else:
                line_tfidf.append(0.0)

        if line_tfidf:
            # content_tfidf.append(max(line_tfidf))
            line_tfidf.sort(reverse=True)
            content_tfidf.append(sum(line_tfidf[0:tfidf_max_num]) / tfidf_max_num)
        else:
            content_tfidf.append(0.0)

        if not (sen_vec_method in [1, 2, 3] and tfidf and avg_tfidf):
            if word_num > 0:
                line_vec = line_vec / word_num
                # print word_num, line_vec
                # print '---do.mean.words-----'

        matrix_content.append(line_vec)

    return matrix_content, content_tfidf


"""
generate oneline-vec ansj
"""


def matrix_line_ansj(content, model, tfidf=None, avg_tfidf=None, tfidf_max_num=1,
                     ansj_serve_url=None, sen_vec_method=0, dim=100):
    """
    :param content: line-contnet to generate matrix
    :param model: word-vector-model-learned
    :param tfidf: all-files-tfidf number
    :param avg_tfidf: max-min-avg tfidf-number
    :param tfidf_max_num: every-line-weight generated by tfidf-num
    :param ansj_serve_url: ansjseg-java-servlet
    :param sen_vec_method: if weight-vector
    :param dim: word-vector-dim
    :return:
    """
    if not content or not model or not ansj_serve_url:
        return None

    if sys.getdefaultencoding() != 'utf-8':
        reload(sys)
        sys.setdefaultencoding('utf-8')

    line_list = seg_sentence(content)

    # 'ansjseg'.jion(list_sent)
    union_sent = ''
    for i in range(len(line_list) - 1):
        union_sent += line_list[i] + 'ansjseg'
    union_sent += line_list[len(line_list) - 1]
    # begin ansj-java-servlet
    ansj_seg = seg_cont_ansj(to_seg_content=union_sent, ansj_serve_url=ansj_serve_url)

    # deal seged-words
    seg_vec = ansj_seg.strip(' \r\n').split('ansjseg')

    matrix_content = list()
    content_tfidf = list()

    for line_one in seg_vec:
        if line_one == '\n' or line_one == '\n\n':
            continue

        line_vec = np.zeros(dim)
        line_tfidf = list()
        word_num = 0

        words = line_one.split()
        for word in words:
            word = ''.join(word.split())
            if word == ' ' or word == '\n' or word == '\n\n':
                continue

            # line-vector
            if sen_vec_method == 0:
                line_vec += np.array(model[word])
                word_num += 1
            elif sen_vec_method == 1 and tfidf and avg_tfidf:
                if word.encode('utf-8') in tfidf:
                    line_vec += np.array(model[word]) * tfidf[word.encode('utf-8')]
            else:
                line_vec += np.array(model[word])
                word_num += 1

            # line-weight
            if tfidf and word.encode('utf-8') in tfidf:
                line_tfidf.append(tfidf[word.encode('utf-8')])
            elif avg_tfidf:
                line_tfidf.append(avg_tfidf['mininum'])
            else:
                line_tfidf.append(0.0)

        if line_tfidf:
            line_tfidf.sort(reverse=True)
            content_tfidf.append(sum(line_tfidf[0:tfidf_max_num]) / tfidf_max_num)
        else:
            content_tfidf.append(0.0)

        if not (sen_vec_method == 1 and tfidf and avg_tfidf):
            if word_num > 0:
                line_vec = line_vec / word_num

        matrix_content.append(line_vec)

    return matrix_content, content_tfidf


"""
load weight-tfidf
"""


def weight_tfidf(whole_tfidf_file, avg_tfidf_file):
    """
    :param whole_tfidf_file:
    :param avg_tfidf_file:
    :return:
    """
    if not (whole_tfidf_file and os.path.exists(whole_tfidf_file)) \
            or not (avg_tfidf_file and os.path.exists(avg_tfidf_file)):
        return None, None

    words_tfidf = dict()
    avg_tfidf = dict()
    file_tfidf = None
    file_avg_tfidf = None
    try:
        file_tfidf = open(whole_tfidf_file, 'r')
        line_tfidf = file_tfidf.readline()
        while line_tfidf:
            key_val = line_tfidf.strip(' \r\n').split(' ')
            words_tfidf[key_val[0]] = float(key_val[1])
            line_tfidf = file_tfidf.readline()
        file_tfidf.close()
        time.sleep(0)

        file_avg_tfidf = open(avg_tfidf_file, 'r')
        avg_line_tfidf = file_avg_tfidf.read()
        line_list = avg_line_tfidf.strip(' \r\n').split('\n')
        for line in line_list:
            data_list = line.split()
            if data_list[0] == 'average:':
                avg_tfidf['average'] = float(data_list[1])
            elif data_list[0] == 'maxinum:':
                avg_tfidf['maxinum'] = float(data_list[1])
            elif data_list[0] == 'mininum:':
                avg_tfidf['mininum'] = float(data_list[1])
        file_avg_tfidf.close()
        time.sleep(0)
    except Exception, e:
        print Exception, e
    finally:
        if file_tfidf and not file_tfidf.closed:
            file_tfidf.close()
        if file_avg_tfidf and not file_avg_tfidf.closed:
            file_avg_tfidf.close()

    return words_tfidf, avg_tfidf


"""
generate anyou-file-vec-weight (can weight vec)
input: file-to-vec, tfidf-file-generated, word-vec-model, ansj-serve-ornot
output: file-vec, file-everyline-weight, data storage in file
"""


def matrix_anyou_vec_weight(file_obj=None, dir_text_tfidf=None, word_vec_model=None, words_max_tfidf=1,
                            ansj_serve_url=None, sen_vec=0, dim=100):
    """
    :param file_obj:
    :param dir_text_tfidf:
    :param word_vec_model:
    :param words_max_tfidf:
    :param ansj_serve_url:
    :param sen_vec:
    :param dim:
    :return:
    """
    if not (file_obj and os.path.exists(file_obj)) or not word_vec_model:
        return

    if not (dir_text_tfidf and len(dir_text_tfidf) == 3):
        return

    file_object = None
    file_vector = None
    content_tfidf = None
    try:
        file_ti = None
        file_avg_ti = None
        file_vec = None
        content_ti = None
        if dir_text_tfidf and ansj_serve_url:
            # make anyou-vec-text
            date_span = re.search(r'\d+', file_obj).span()
            # file-vec-out-fir
            if not os.path.exists(dir_text_tfidf['dir_text']):
                os.mkdir(dir_text_tfidf['dir_text'])
            file_vec = dir_text_tfidf['dir_text'] + file_obj[date_span[0]:date_span[1]] + '.txt.out.ansj.vect'
            # file-line-weight-out-dir
            if not os.path.exists(dir_text_tfidf['text_tfidf']):
                os.mkdir(dir_text_tfidf['text_tfidf'])
            content_ti = dir_text_tfidf['text_tfidf'] + file_obj[date_span[0]:date_span[1]] + '.txt.content.ansj.tfidf'
            # file-words-tfidf
            if dir_text_tfidf['dir_tfidf']:
                file_ti = dir_text_tfidf['dir_tfidf'] + file_obj[date_span[0]:date_span[1]] + '.txt.ansj.tfidf'
                file_avg_ti = dir_text_tfidf['dir_tfidf'] + 'average.txt.ansj.tfidf'
        elif dir_text_tfidf:
            # make anyou-vec-text
            date_span = re.search(r'\d+', file_obj).span()

            if not os.path.exists(dir_text_tfidf['dir_text']):
                os.mkdir(dir_text_tfidf['dir_text'])
            file_vec = dir_text_tfidf['dir_text'] + file_obj[date_span[0]:date_span[1]] + '.txt.out.vect'

            if not os.path.exists(dir_text_tfidf['text_tfidf']):
                os.mkdir(dir_text_tfidf['text_tfidf'])
            content_ti = dir_text_tfidf['text_tfidf'] + file_obj[date_span[0]:date_span[1]] + '.txt.content.tfidf'

            if dir_text_tfidf['dir_tfidf']:
                file_ti = dir_text_tfidf['dir_tfidf'] + file_obj[date_span[0]:date_span[1]] + '.txt.tfidf'
                file_avg_ti = dir_text_tfidf['dir_tfidf'] + 'average.txt.tfidf'

        words_tfidf, avg_tfidf = weight_tfidf(file_ti, file_avg_ti)

        file_object = open(file_obj)
        file_vector = open(file_vec, 'w')
        content_tfidf = open(content_ti, 'w')
        line = file_object.readline()

        while line:
            matrix_content = list()
            vec_tfidf = list()
            if ansj_serve_url:
                matrix_content, vec_tfidf = \
                    matrix_line_ansj(content=line, model=word_vec_model, tfidf=words_tfidf, avg_tfidf=avg_tfidf,
                                     tfidf_max_num=words_max_tfidf, ansj_serve_url=ansj_serve_url,
                                     sen_vec_method=sen_vec, dim=dim)
            else:
                matrix_content, vec_tfidf = \
                    matrix_line_jieba(content=line, model=word_vec_model, tfidf=words_tfidf, avg_tfidf=avg_tfidf,
                                      tfidf_max_num=words_max_tfidf, sen_vec_method=sen_vec, dim=dim)

            if matrix_content and vec_tfidf:

                # model-mean-anyou
                # sum_line = np.zeros(dim)
                # for line in matrix_content:
                #     sum_line += line
                # sum_line = sum_line / len(matrix_content)
                # for one_num in sum_line:
                #     file_vector.write(str(one_num) + ' ')
                # file_vector.write('\n')

                # model-every-line
                for line_vec in matrix_content:
                    for number in line_vec:
                        file_vector.write((str(number) + ' ').encode('utf-8'))
                file_vector.write('\n'.encode('utf-8'))

                for line_vec in vec_tfidf:
                    content_tfidf.write((str(line_vec) + ' ').encode('utf-8'))
                content_tfidf.write('\n'.encode('utf-8'))

            line = file_object.readline()
            # print '---on---'

        file_object.close()
        time.sleep(0)
        file_vector.close()
        time.sleep(0)
        content_tfidf.close()
        time.sleep(0)

    except Exception, e:
        print Exception, e
    finally:
        if file_object and not file_object.closed:
            file_object.close()
        if file_vector and not file_vector.closed:
            file_vector.close()
        if content_tfidf and content_tfidf.closed:
            content_tfidf.close()


"""
generate similar-text-vec (no weight)
input: content-str, word-vec-model-file, ansj-serve-ornot
output: file-vec-out-path, data-storage-in-file
"""


def matrix_similar_src(content, file_vec=None, file_model=None, ansj_serve_url=None, dim=100):
    """
    :param content:
    :param file_vec:
    :param file_model:
    :param ansj_serve_url:
    :param dim:
    :return:
    """
    if not content or not file_vec or not (file_model and os.path.exists(file_model)):
        return

    file_vector = None
    try:
        file_vector = open(file_vec, 'w')
        model = load_model(file_model)
        # print 'load model'

        matrix_content = list()
        vec_tfidf = list()
        if ansj_serve_url:
            matrix_content, vec_tfidf = \
                matrix_line_ansj(content=content, model=model, ansj_serve_url=ansj_serve_url, dim=dim)
        else:
            matrix_content, vec_tfidf = \
                matrix_line_jieba(content=content, model=model, dim=dim)

        if matrix_content:

            # model-every-line
            for line_vec in matrix_content:
                for number in line_vec:
                    file_vector.write((str(number) + ' ').encode('utf-8'))
            file_vector.write('\n'.encode('utf-8'))

        file_vector.close()
        time.sleep(0)

    except Exception, e:
        print Exception, e
    finally:
        if file_vector and not file_vector.closed:
            file_vector.close()

def matrix_similar_src_modeled(content, file_vec=None, file_model=None, ansj_serve_url=None, dim=100):
    """
    :param content:
    :param file_vec:
    :param file_model:
    :param ansj_serve_url:
    :param dim:
    :return:
    """
    if not content or not file_vec or not file_model:
        return

    file_vector = None
    try:
        file_vector = open(file_vec, 'w')

        matrix_content = list()
        vec_tfidf = list()
        if ansj_serve_url:
            matrix_content, vec_tfidf = \
                matrix_line_ansj(content=content, model=file_model, ansj_serve_url=ansj_serve_url, dim=dim)
        else:
            matrix_content, vec_tfidf = \
                matrix_line_jieba(content=content, model=file_model, dim=dim)

        if matrix_content:

            # model-every-line
            for line_vec in matrix_content:
                for number in line_vec:
                    file_vector.write((str(number) + ' ').encode('utf-8'))
            file_vector.write('\n'.encode('utf-8'))

        file_vector.close()
        time.sleep(0)

    except Exception, e:
        print Exception, e
    finally:
        if file_vector and not file_vector.closed:
            file_vector.close()


"""
generate file-text-vec (can weight), for test
input: file-to-vec, tfidf-file-generated, word-vec-model-file, ansj-serve-ornot, ---file-path-input
output: file-vec, file-everyline-weight, data storage in file
"""


def matrix_file_vec_weight(file_obj=None, file_text_tfidf=None, file_model=None, words_max_tfidf=1,
                           ansj_serve_url=None, sen_vec=0, dim=100):
    """
    :param file_obj:
    :param file_text_tfidf:
    :param file_model:
    :param words_max_tfidf:
    :param ansj_serve_url:
    :param sen_vec:
    :param dim:
    :return:
    """
    if not (file_obj and os.path.exists(file_obj)) or not (file_model and os.path.exists(file_model)):
        return

    if not (file_text_tfidf and len(file_text_tfidf) == 2):
        return

    file_object = None
    file_vector = None
    try:
        file_ti = None
        file_avg_ti = None
        file_vec = None
        if file_text_tfidf:
            # make test-vec-sample
            file_vec = file_text_tfidf['file_text']
            if file_text_tfidf['file_tfidf']:
                file_ti = file_text_tfidf['file_tfidf']
                file_avg_ti = file_ti[:(file_ti.rindex('/') + 1)] + 'average.txt.tfidf'

        words_tfidf, avg_tfidf = weight_tfidf(file_ti, file_avg_ti)

        file_object = open(file_obj)
        file_vector = open(file_vec, 'w')
        line = file_object.readline()
        model = load_model(file_model)
        # print 'load model'

        while line and model:

            matrix_content = list()
            vec_tfidf = list()
            if ansj_serve_url:
                matrix_content, vec_tfidf = \
                    matrix_line_ansj(content=line, model=model, tfidf=words_tfidf, avg_tfidf=avg_tfidf,
                                     tfidf_max_num=words_max_tfidf, ansj_serve_url=ansj_serve_url,
                                     sen_vec_method=sen_vec, dim=dim)
            else:
                matrix_content, vec_tfidf = \
                    matrix_line_jieba(content=line, model=model, tfidf=words_tfidf, avg_tfidf=avg_tfidf,
                                      tfidf_max_num=words_max_tfidf, sen_vec_method=sen_vec, dim=dim)

            if matrix_content:

                # model-mean-anyou
                # sum_line = np.zeros(dim)
                # for line in matrix_content:
                #     sum_line += line
                # sum_line = sum_line / len(matrix_content)
                # for one_num in sum_line:
                #     file_vector.write(str(one_num) + ' ')
                # file_vector.write('\n')

                # model-every-line
                for line_vec in matrix_content:
                    for number in line_vec:
                        file_vector.write((str(number) + ' ').encode('utf-8'))
                file_vector.write('\n'.encode('utf-8'))

            line = file_object.readline()
            # print '---on---'

        file_object.close()
        time.sleep(0)
        file_vector.close()
        time.sleep(0)

    except Exception, e:
        print Exception, e
    finally:
        if file_object and not file_object.closed:
            file_object.close()
        if file_vector and not file_vector.closed:
            file_vector.close()


"""
generate similar-text-vec (no weight), for text
input: content-file-oneline, word-vec-model-file, ansj-serve-ornot
output: file-vec-out, data-in-RAM
"""


def matrix_file_vec(file_obj=None, file_model=None, ansj_serve_url=None, dim=100):
    """
    :param file_obj:
    :param file_model:
    :param ansj_serve_url:
    :param dim:
    :return:
    """
    if not (file_obj and os.path.exists(file_obj)) or not (file_model and os.path.exists(file_model)):
        return

    file_object = None
    matrix_content = list()
    vec_tfidf = list()
    try:
        file_object = open(file_obj)
        line = file_object.readline()
        file_object.close()
        time.sleep(0)
        model = load_model(file_model)
        # print 'load model'

        if line and model:

            if ansj_serve_url:
                matrix_content, vec_tfidf = \
                    matrix_line_ansj(content=line, model=model, ansj_serve_url=ansj_serve_url, dim=dim)
            else:
                matrix_content, vec_tfidf = \
                    matrix_line_jieba(content=line, model=model, dim=dim)

    except Exception, e:
        print Exception, e
    finally:
        if file_object and not file_object.closed:
            file_object.close()

    return matrix_content


def matrix_src_vec(content=None, file_model=None, ansj_serve_url=None, dim=100):
    """
    :param content:
    :param file_model:
    :param ansj_serve_url:
    :param dim:
    :return:
    """
    if not content or not (file_model and os.path.exists(file_model)):
        return

    matrix_content = list()
    try:

        model = load_model(file_model)
        # print 'load model'

        if model:

            if ansj_serve_url:
                matrix_content, vec_tfidf = \
                    matrix_line_ansj(content=content, model=model, ansj_serve_url=ansj_serve_url, dim=dim)
            else:
                matrix_content, vec_tfidf = \
                    matrix_line_jieba(content=content, model=model, dim=dim)

    except Exception, e:
        print Exception, e
    finally:
        pass

    return matrix_content
